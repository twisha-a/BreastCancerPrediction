{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.stats import zscore\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ],
      "metadata": {
        "id": "kQDQ5DSyc6lZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1 : Preprocessing"
      ],
      "metadata": {
        "id": "kA-XlLoYWZag"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5Vbgz8lJgb0",
        "outputId": "03e544c5-c2a2-46d8-b252-4821df83a4b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Age                       201\n",
            "Race                      402\n",
            "Marital Status            321\n",
            "T Stage                     0\n",
            "N Stage                     0\n",
            "6th Stage                   0\n",
            "differentiate               0\n",
            "Grade                       0\n",
            "A Stage                     0\n",
            "Tumor Size                402\n",
            "Estrogen Status           201\n",
            "Progesterone Status         0\n",
            "Regional Node Examined    603\n",
            "Reginol Node Positive       0\n",
            "Survival Months             0\n",
            "Status                      0\n",
            "dtype: int64\n",
            "        Age  Tumor Size  Regional Node Examined  Reginol Node Positive  \\\n",
            "0  1.608907   -1.306632                1.280868              -0.618172   \n",
            "1 -0.449611    0.218417               -0.046684               0.164807   \n",
            "2  0.465286    1.595881               -0.046684               0.556296   \n",
            "3  0.465286    0.000000               -1.639745              -0.618172   \n",
            "4 -0.792697    0.513588               -1.506990              -0.618172   \n",
            "\n",
            "   Survival Months  Race_Other  Race_White  Marital Status_Married  \\\n",
            "0        -0.492961         0.0         1.0                     1.0   \n",
            "1        -0.405695         0.0         1.0                     1.0   \n",
            "2         0.161530         0.0         1.0                     0.0   \n",
            "3         0.554224         0.0         1.0                     1.0   \n",
            "4        -0.929288         0.0         1.0                     1.0   \n",
            "\n",
            "   Marital Status_Separated  Marital Status_Single   ...  \\\n",
            "0                       0.0                     0.0  ...   \n",
            "1                       0.0                     0.0  ...   \n",
            "2                       0.0                     0.0  ...   \n",
            "3                       0.0                     0.0  ...   \n",
            "4                       0.0                     0.0  ...   \n",
            "\n",
            "   differentiate_Poorly differentiated  differentiate_Undifferentiated  \\\n",
            "0                                  1.0                             0.0   \n",
            "1                                  0.0                             0.0   \n",
            "2                                  0.0                             0.0   \n",
            "3                                  1.0                             0.0   \n",
            "4                                  1.0                             0.0   \n",
            "\n",
            "   differentiate_Well differentiated  Grade_1  Grade_2  Grade_3  \\\n",
            "0                                0.0      0.0      0.0      1.0   \n",
            "1                                0.0      0.0      1.0      0.0   \n",
            "2                                0.0      0.0      1.0      0.0   \n",
            "3                                0.0      0.0      0.0      1.0   \n",
            "4                                0.0      0.0      0.0      1.0   \n",
            "\n",
            "   A Stage_Regional  Estrogen Status_Positive  Progesterone Status_Positive  \\\n",
            "0               1.0                       1.0                           1.0   \n",
            "1               1.0                       1.0                           1.0   \n",
            "2               1.0                       1.0                           1.0   \n",
            "3               1.0                       1.0                           1.0   \n",
            "4               1.0                       1.0                           1.0   \n",
            "\n",
            "   Status_Dead  \n",
            "0          0.0  \n",
            "1          0.0  \n",
            "2          0.0  \n",
            "3          0.0  \n",
            "4          0.0  \n",
            "\n",
            "[5 rows x 30 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Step 1: Load Data\n",
        "# data = pd.read_csv('https://drive.google.com/file/d/1WXAFHw2AMZg7pf2VjadF1sKEETguJwdT/export?format=csv')  # Replace with your actual file path\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Access the file from Google Drive\n",
        "data = pd.read_csv('/content/drive/My Drive/Breast_Cancer_dataset.csv')\n",
        "\n",
        "# Splitting the dataset on column Status\n",
        "X = data.drop(columns=['Status'])  # Replace 'Survival_Status' with your target column\n",
        "y = data['Status']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Encoding categorical features if present in X_train or X_test\n",
        "for col in X_train.columns:\n",
        "    if X_train[col].dtype == 'object':\n",
        "        le = LabelEncoder()\n",
        "        X_train[col] = le.fit_transform(X_train[col].astype(str))\n",
        "        X_test[col] = le.transform(X_test[col].astype(str))\n",
        "\n",
        "# Ensure data is fully numeric and handle missing values\n",
        "X_train = X_train.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
        "X_test = X_test.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
        "# Step 2: Handle Missing Values\n",
        "# Display missing values for each column\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Impute missing values for numerical columns with the mean or median\n",
        "num_imputer = SimpleImputer(strategy='mean')\n",
        "data[data.select_dtypes(include=['float64', 'int64']).columns] = num_imputer.fit_transform(data.select_dtypes(include=['float64', 'int64']))\n",
        "\n",
        "# Impute missing values for categorical columns with the most frequent value\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "data[data.select_dtypes(include=['object']).columns] = cat_imputer.fit_transform(data.select_dtypes(include=['object']))\n",
        "\n",
        "# Step 3: Outlier Detection and Handling (using Z-score)\n",
        "# Applying Z-score to numerical columns\n",
        "numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
        "data_no_outliers = data[(np.abs(zscore(data[numeric_cols])) < 3).all(axis=1)]  # Keeping rows with Z-score < 3\n",
        "\n",
        "# Step 4: Standardization/Normalization of Numerical Features\n",
        "scaler = StandardScaler()\n",
        "data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
        "\n",
        "# Step 5: Encoding Categorical Features\n",
        "# One-Hot Encoding for categorical columns\n",
        "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
        "categorical_cols = data.select_dtypes(include=['object']).columns\n",
        "encoded_cat_data = pd.DataFrame(encoder.fit_transform(data[categorical_cols]), columns=encoder.get_feature_names_out(categorical_cols))\n",
        "\n",
        "# Concatenate encoded columns back to the dataset\n",
        "data = pd.concat([data.drop(categorical_cols, axis=1), encoded_cat_data], axis=1)\n",
        "\n",
        "# Step 6: Dimensionality Reduction (Optional)\n",
        "# Apply PCA if you have a large number of features and want to reduce dimensionality\n",
        "pca = PCA(n_components=0.95)  # Retain 95% variance\n",
        "data_reduced = pca.fit_transform(data)\n",
        "\n",
        "# Display the preprocessed data\n",
        "print(data.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HvSK3FgbWWBu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DRrzXLgcWYYx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Modeling"
      ],
      "metadata": {
        "id": "XPlB6vPFpCT-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN"
      ],
      "metadata": {
        "id": "LvGJ-WC4pP6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# KNN function implemented from scratch\n",
        "class KNN:\n",
        "    def __init__(self, k=3):\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        self.X_train = X_train.values  # Convert X_train to NumPy array\n",
        "        self.y_train = y_train.values # Convert y_train to NumPy array\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        X_test = X_test.values # Convert X_test to NumPy array\n",
        "        predictions = [self._predict(x) for x in X_test]\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def _predict(self, x):\n",
        "        # Compute distances to all points in the training set\n",
        "        distances = [np.linalg.norm(x - x_train) for x_train in self.X_train]\n",
        "        # Get the k nearest samples, labels\n",
        "        k_indices = np.argsort(distances)[:self.k]\n",
        "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
        "        # Majority vote\n",
        "        most_common = Counter(k_nearest_labels).most_common(1)\n",
        "        return most_common[0][0]\n",
        "\n",
        "# Initialize, fit, and predict with our KNN implementation\n",
        "knn = KNN(k=5)\n",
        "knn.fit(X_train, y_train)\n",
        "knn_pred = knn.predict(X_test)\n",
        "# knn_pred"
      ],
      "metadata": {
        "id": "xePdStWKWTNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naïve Bayes"
      ],
      "metadata": {
        "id": "Av5K7SmJp71X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Train and predict with Naive Bayes\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "nb_pred = nb.predict(X_test)\n"
      ],
      "metadata": {
        "id": "6BfqJXl_WTj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C4.5 Decision Tree"
      ],
      "metadata": {
        "id": "4tQbRfIvp9SV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Train and predict with Decision Tree\n",
        "dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5)\n",
        "dt.fit(X_train, y_train)\n",
        "dt_pred = dt.predict(X_test)\n"
      ],
      "metadata": {
        "id": "uLpvc_1hWTnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "y-X4VVO2p-SE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Train and predict with Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_pred = rf.predict(X_test)\n"
      ],
      "metadata": {
        "id": "-DyO4kTYWTq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Boosting"
      ],
      "metadata": {
        "id": "QNJEDpNHp_bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Train and predict with Gradient Boosting\n",
        "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "gb.fit(X_train, y_train)\n",
        "gb_pred = gb.predict(X_test)\n"
      ],
      "metadata": {
        "id": "Hhn4CcUqiANa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Networks"
      ],
      "metadata": {
        "id": "EyyGGgRSqAl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Train and predict with Neural Network\n",
        "nn = MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000, random_state=42)\n",
        "nn.fit(X_train, y_train)\n",
        "nn_pred = nn.predict(X_test)\n"
      ],
      "metadata": {
        "id": "OUzoDCnxiY6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "AoDE7Gg1qFcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Hyperparameter tuning for Random Forest\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [5, 10, 15],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "rf_grid_search = GridSearchCV(RandomForestClassifier(random_state=42), rf_param_grid, cv=5)\n",
        "rf_grid_search.fit(X_train, y_train)\n",
        "print(\"Best Random Forest Params:\", rf_grid_search.best_params_)\n",
        "print(\"Best Random Forest Score:\", rf_grid_search.best_score_)\n",
        "\n",
        "# Hyperparameter tuning for Gradient Boosting\n",
        "gb_param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7]\n",
        "}\n",
        "gb_grid_search = GridSearchCV(GradientBoostingClassifier(random_state=42), gb_param_grid, cv=5)\n",
        "gb_grid_search.fit(X_train, y_train)\n",
        "print(\"Best Gradient Boosting Params:\", gb_grid_search.best_params_)\n",
        "print(\"Best Gradient Boosting Score:\", gb_grid_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uQRkaiRis_p",
        "outputId": "6dafb394-75f2-480f-da3b-5b6b6d87ba15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Random Forest Params: {'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 100}\n",
            "Best Random Forest Score: 0.903696280053708\n",
            "Best Gradient Boosting Params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
            "Best Gradient Boosting Score: 0.9005897240226808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "\n",
        "# Store the predictions for each model\n",
        "model_predictions = {\n",
        "    'KNN': knn_pred,\n",
        "    'Naive Bayes': nb_pred,\n",
        "    'Decision Tree': dt_pred,\n",
        "    'Random Forest': rf_pred,\n",
        "    'Gradient Boosting': gb_pred,\n",
        "    'Neural Network': nn_pred\n",
        "}\n",
        "\n",
        "# Initialize a list to store the result summary\n",
        "results_summary = []\n",
        "\n",
        "# Calculate metrics for each model\n",
        "for model_name, predictions in model_predictions.items():\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    precision = precision_score(y_test, predictions, average='weighted')\n",
        "    recall = recall_score(y_test, predictions, average='weighted')\n",
        "    f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "    # Append results to the summary list\n",
        "    results_summary.append({\n",
        "        'Model': model_name,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1\n",
        "    })\n",
        "\n",
        "# Convert results summary to DataFrame\n",
        "results_df = pd.DataFrame(results_summary)\n",
        "print(\"Model Performance Summary:\")\n",
        "print(results_df)\n",
        "\n",
        "# Display feature importance for models that have it\n",
        "feature_importances = {\n",
        "    'Random Forest': rf.feature_importances_,\n",
        "    'Gradient Boosting': gb.feature_importances_\n",
        "}\n",
        "\n",
        "for model_name, importances in feature_importances.items():\n",
        "    feature_importance_df = pd.DataFrame({\n",
        "        'Feature': X.columns,\n",
        "        'Importance': importances\n",
        "    }).sort_values(by='Importance', ascending=False)\n",
        "    print(f\"\\nFeature Importance for {model_name}:\")\n",
        "    print(feature_importance_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svK506oSkKAp",
        "outputId": "6341c65b-1c2c-4d2f-97e2-00ad1d8899e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance Summary:\n",
            "               Model  Accuracy  Precision    Recall  F1 Score\n",
            "0                KNN  0.885714   0.873081  0.885714  0.872689\n",
            "1        Naive Bayes  0.847205   0.850912  0.847205  0.848978\n",
            "2      Decision Tree  0.913043   0.907968  0.913043  0.904636\n",
            "3      Random Forest  0.909317   0.912353  0.909317  0.893871\n",
            "4  Gradient Boosting  0.900621   0.892311  0.900621  0.892093\n",
            "5     Neural Network  0.894410   0.885450  0.894410  0.880074\n",
            "\n",
            "Feature Importance for Random Forest:\n",
            "                   Feature  Importance\n",
            "14         Survival Months    0.585354\n",
            "13   Reginol Node Positive    0.071184\n",
            "4                  N Stage    0.058566\n",
            "0                      Age    0.044557\n",
            "9               Tumor Size    0.040039\n",
            "5                6th Stage    0.039734\n",
            "10         Estrogen Status    0.038408\n",
            "11     Progesterone Status    0.034703\n",
            "12  Regional Node Examined    0.021924\n",
            "7                    Grade    0.020117\n",
            "3                 T Stage     0.013860\n",
            "2           Marital Status    0.010201\n",
            "1                     Race    0.009991\n",
            "6            differentiate    0.007913\n",
            "8                  A Stage    0.003449\n",
            "\n",
            "Feature Importance for Gradient Boosting:\n",
            "                   Feature  Importance\n",
            "14         Survival Months    0.720774\n",
            "0                      Age    0.071988\n",
            "13   Reginol Node Positive    0.058620\n",
            "9               Tumor Size    0.026124\n",
            "11     Progesterone Status    0.021986\n",
            "12  Regional Node Examined    0.018589\n",
            "5                6th Stage    0.014661\n",
            "7                    Grade    0.014482\n",
            "10         Estrogen Status    0.013848\n",
            "1                     Race    0.011731\n",
            "4                  N Stage    0.009602\n",
            "3                 T Stage     0.007538\n",
            "2           Marital Status    0.006961\n",
            "6            differentiate    0.003096\n",
            "8                  A Stage    0.000000\n"
          ]
        }
      ]
    }
  ]
}